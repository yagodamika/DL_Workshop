{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **How To Generate an Image**\n",
        "1. Pick an ImageNet class, and find its number.\n",
        "All class numbers can be found here: https://deeplearning.cms.waikato.ac.nz/user-guide/class-maps/IMAGENET/\n",
        "2. Change the variable class_number accordingly in the code cell below.\n",
        "3. Change the variable class_name accordingly in the code cell below.\n",
        "4. Run all cells below in their order.\n",
        "6. Wait for the code to stop running.\n",
        "\n",
        "You can find the result in a folder named OUTPUTS/class_name , where class_name is replaced with the value of this variable."
      ],
      "metadata": {
        "id": "35Dn3G7rh0MO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CHANGE THE VARIABLES BELOW\n",
        "class_number = 0\n",
        "class_name = \"tench\""
      ],
      "metadata": {
        "id": "bAi-V785h94T"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d60zXspZ7a6a"
      },
      "source": [
        "**Mount**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1izI9hbP7cKY",
        "outputId": "8ca51ced-383e-432c-f3b3-ac1ee9af311d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n",
            "/content/drive/My Drive/workshop\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "\n",
        "%cd '/content/drive/My Drive/workshop'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qd4WlFG7_CP2"
      },
      "source": [
        "**GPU**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5VAzXek_FfV",
        "outputId": "b8df75e2-7b18-4475-af49-0dc25c43af6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Oct  3 12:32:32 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKtBVSgR7cpr"
      },
      "source": [
        "**Imports**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bceQoFW7eLl",
        "outputId": "45595e19-ee7a-440c-f333-c63951055507"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting kornia\n",
            "  Downloading kornia-0.7.0-py2.py3-none-any.whl (705 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/705.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/705.7 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m696.3/705.7 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m705.7/705.7 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from kornia) (23.1)\n",
            "Requirement already satisfied: torch>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from kornia) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.9.1->kornia) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.9.1->kornia) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9.1->kornia) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.9.1->kornia) (1.3.0)\n",
            "Installing collected packages: kornia\n",
            "Successfully installed kornia-0.7.0\n",
            "Collecting madgrad\n",
            "  Downloading madgrad-1.3.tar.gz (7.9 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: madgrad\n",
            "  Building wheel for madgrad (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for madgrad: filename=madgrad-1.3-py3-none-any.whl size=11867 sha256=9ffdb42b0a8d95bb2e7e27e9945d90b74d791bda04a3097ee34c0a8d2d74dcf0\n",
            "  Stored in directory: /root/.cache/pip/wheels/d9/a3/83/7ed1ddc517cd87cad4e3a4aec7f8ea1d5e83a5ff282e51490a\n",
            "Successfully built madgrad\n",
            "Installing collected packages: madgrad\n",
            "Successfully installed madgrad-1.3\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim\n",
        "import time\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "import torchvision.transforms.functional as TF\n",
        "import torchvision.transforms as T\n",
        "import random\n",
        "from torchvision import transforms\n",
        "import torchvision\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "%pip install kornia\n",
        "%pip install madgrad\n",
        "\n",
        "import kornia\n",
        "import kornia.augmentation as K\n",
        "from madgrad import MADGRAD\n",
        "from torchvision.models import inception_v3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9i7Ldf679Uu5"
      },
      "source": [
        "**Deep Image Prior**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "NUWGg9lI9WbO"
      },
      "outputs": [],
      "source": [
        "def add_module(self, module):\n",
        "\tself.add_module(str(len(self) + 1), module)\n",
        "\n",
        "\n",
        "torch.nn.Module.add = add_module\n",
        "\n",
        "# @title\n",
        "class Downsampler(nn.Module):\n",
        "\t'''\n",
        "\t\thttp://www.realitypixels.com/turk/computergraphics/ResamplingFilters.pdf\n",
        "\t'''\n",
        "\n",
        "\tdef __init__(self, n_planes, factor, kernel_type, phase=0, kernel_width=None, support=None, sigma=None,\n",
        "\t\t\t\t preserve_size=False):\n",
        "\t\tsuper(Downsampler, self).__init__()\n",
        "\n",
        "\t\tassert phase in [0, 0.5], 'phase should be 0 or 0.5'\n",
        "\n",
        "\t\tif kernel_type == 'lanczos2':\n",
        "\t\t\tsupport = 2\n",
        "\t\t\tkernel_width = 4 * factor + 1\n",
        "\t\t\tkernel_type_ = 'lanczos'\n",
        "\n",
        "\t\telif kernel_type == 'lanczos3':\n",
        "\t\t\tsupport = 3\n",
        "\t\t\tkernel_width = 6 * factor + 1\n",
        "\t\t\tkernel_type_ = 'lanczos'\n",
        "\n",
        "\t\telif kernel_type == 'gauss12':\n",
        "\t\t\tkernel_width = 7\n",
        "\t\t\tsigma = 1 / 2\n",
        "\t\t\tkernel_type_ = 'gauss'\n",
        "\n",
        "\t\telif kernel_type == 'gauss1sq2':\n",
        "\t\t\tkernel_width = 9\n",
        "\t\t\tsigma = 1. / np.sqrt(2)\n",
        "\t\t\tkernel_type_ = 'gauss'\n",
        "\n",
        "\t\telif kernel_type in ['lanczos', 'gauss', 'box']:\n",
        "\t\t\tkernel_type_ = kernel_type\n",
        "\n",
        "\t\telse:\n",
        "\t\t\tassert False, 'wrong name kernel'\n",
        "\n",
        "\t\t# note that `kernel width` will be different to actual size for phase = 1/2\n",
        "\t\tself.kernel = get_kernel(factor, kernel_type_, phase, kernel_width, support=support, sigma=sigma)\n",
        "\n",
        "\t\tdownsampler = nn.Conv2d(n_planes, n_planes, kernel_size=self.kernel.shape, stride=factor, padding=0)\n",
        "\t\tdownsampler.weight.data[:] = 0\n",
        "\t\tdownsampler.bias.data[:] = 0\n",
        "\n",
        "\t\tkernel_torch = torch.from_numpy(self.kernel)\n",
        "\t\tfor i in range(n_planes):\n",
        "\t\t\tdownsampler.weight.data[i, i] = kernel_torch\n",
        "\n",
        "\t\tself.downsampler_ = downsampler\n",
        "\n",
        "\t\tif preserve_size:\n",
        "\n",
        "\t\t\tif self.kernel.shape[0] % 2 == 1:\n",
        "\t\t\t\tpad = int((self.kernel.shape[0] - 1) / 2.)\n",
        "\t\t\telse:\n",
        "\t\t\t\tpad = int((self.kernel.shape[0] - factor) / 2.)\n",
        "\n",
        "\t\t\tself.padding = nn.ReplicationPad2d(pad)\n",
        "\n",
        "\t\tself.preserve_size = preserve_size\n",
        "\n",
        "\tdef forward(self, input):\n",
        "\t\tif self.preserve_size:\n",
        "\t\t\tx = self.padding(input)\n",
        "\t\telse:\n",
        "\t\t\tx = input\n",
        "\t\tself.x = x\n",
        "\t\treturn self.downsampler_(x)\n",
        "\n",
        "\n",
        "def get_kernel(factor, kernel_type, phase, kernel_width, support=None, sigma=None):\n",
        "\tassert kernel_type in ['lanczos', 'gauss', 'box']\n",
        "\n",
        "\t# factor  = float(factor)\n",
        "\tif phase == 0.5 and kernel_type != 'box':\n",
        "\t\tkernel = np.zeros([kernel_width - 1, kernel_width - 1])\n",
        "\telse:\n",
        "\t\tkernel = np.zeros([kernel_width, kernel_width])\n",
        "\n",
        "\tif kernel_type == 'box':\n",
        "\t\tassert phase == 0.5, 'Box filter is always half-phased'\n",
        "\t\tkernel[:] = 1. / (kernel_width * kernel_width)\n",
        "\n",
        "\telif kernel_type == 'gauss':\n",
        "\t\tassert sigma, 'sigma is not specified'\n",
        "\t\tassert phase != 0.5, 'phase 1/2 for gauss not implemented'\n",
        "\n",
        "\t\tcenter = (kernel_width + 1.) / 2.\n",
        "\t\tprint(center, kernel_width)\n",
        "\t\tsigma_sq = sigma * sigma\n",
        "\n",
        "\t\tfor i in range(1, kernel.shape[0] + 1):\n",
        "\t\t\tfor j in range(1, kernel.shape[1] + 1):\n",
        "\t\t\t\tdi = (i - center) / 2.\n",
        "\t\t\t\tdj = (j - center) / 2.\n",
        "\t\t\t\tkernel[i - 1][j - 1] = np.exp(-(di * di + dj * dj) / (2 * sigma_sq))\n",
        "\t\t\t\tkernel[i - 1][j - 1] = kernel[i - 1][j - 1] / (2. * np.pi * sigma_sq)\n",
        "\telif kernel_type == 'lanczos':\n",
        "\t\tassert support, 'support is not specified'\n",
        "\t\tcenter = (kernel_width + 1) / 2.\n",
        "\n",
        "\t\tfor i in range(1, kernel.shape[0] + 1):\n",
        "\t\t\tfor j in range(1, kernel.shape[1] + 1):\n",
        "\n",
        "\t\t\t\tif phase == 0.5:\n",
        "\t\t\t\t\tdi = abs(i + 0.5 - center) / factor\n",
        "\t\t\t\t\tdj = abs(j + 0.5 - center) / factor\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tdi = abs(i - center) / factor\n",
        "\t\t\t\t\tdj = abs(j - center) / factor\n",
        "\n",
        "\t\t\t\tpi_sq = np.pi * np.pi\n",
        "\n",
        "\t\t\t\tval = 1\n",
        "\t\t\t\tif di != 0:\n",
        "\t\t\t\t\tval = val * support * np.sin(np.pi * di) * np.sin(np.pi * di / support)\n",
        "\t\t\t\t\tval = val / (np.pi * np.pi * di * di)\n",
        "\n",
        "\t\t\t\tif dj != 0:\n",
        "\t\t\t\t\tval = val * support * np.sin(np.pi * dj) * np.sin(np.pi * dj / support)\n",
        "\t\t\t\t\tval = val / (np.pi * np.pi * dj * dj)\n",
        "\n",
        "\t\t\t\tkernel[i - 1][j - 1] = val\n",
        "\n",
        "\n",
        "\telse:\n",
        "\t\tassert False, 'wrong method name'\n",
        "\n",
        "\tkernel /= kernel.sum()\n",
        "\n",
        "\treturn kernel\n",
        "\n",
        "class Concat(nn.Module):\n",
        "\tdef __init__(self, dim, *args):\n",
        "\t\tsuper(Concat, self).__init__()\n",
        "\t\tself.dim = dim\n",
        "\n",
        "\t\tfor idx, module in enumerate(args):\n",
        "\t\t\tself.add_module(str(idx), module)\n",
        "\n",
        "\tdef forward(self, input):\n",
        "\t\tinputs = []\n",
        "\t\tfor module in self._modules.values():\n",
        "\t\t\tinputs.append(module(input))\n",
        "\n",
        "\t\tinputs_shapes2 = [x.shape[2] for x in inputs]\n",
        "\t\tinputs_shapes3 = [x.shape[3] for x in inputs]\n",
        "\n",
        "\t\tif np.all(np.array(inputs_shapes2) == min(inputs_shapes2)) and np.all(\n",
        "\t\t\t\tnp.array(inputs_shapes3) == min(inputs_shapes3)):\n",
        "\t\t\tinputs_ = inputs\n",
        "\t\telse:\n",
        "\t\t\ttarget_shape2 = min(inputs_shapes2)\n",
        "\t\t\ttarget_shape3 = min(inputs_shapes3)\n",
        "\n",
        "\t\t\tinputs_ = []\n",
        "\t\t\tfor inp in inputs:\n",
        "\t\t\t\tdiff2 = (inp.size(2) - target_shape2) // 2\n",
        "\t\t\t\tdiff3 = (inp.size(3) - target_shape3) // 2\n",
        "\t\t\t\tinputs_.append(inp[:, :, diff2: diff2 + target_shape2, diff3:diff3 + target_shape3])\n",
        "\n",
        "\t\treturn torch.cat(inputs_, dim=self.dim)\n",
        "\n",
        "\tdef __len__(self):\n",
        "\t\treturn len(self._modules)\n",
        "\n",
        "\n",
        "class GenNoise(nn.Module):\n",
        "\tdef __init__(self, dim2):\n",
        "\t\tsuper(GenNoise, self).__init__()\n",
        "\t\tself.dim2 = dim2\n",
        "\n",
        "\tdef forward(self, input):\n",
        "\t\ta = list(input.size())\n",
        "\t\ta[1] = self.dim2\n",
        "\t\t# print (input.data.type())\n",
        "\n",
        "\t\tb = torch.zeros(a).type_as(input.data)\n",
        "\t\tb.normal_()\n",
        "\n",
        "\t\tx = torch.autograd.Variable(b)\n",
        "\n",
        "\t\treturn x\n",
        "\n",
        "\n",
        "class Swish(nn.Module):\n",
        "\t\"\"\"\n",
        "\t\thttps://arxiv.org/abs/1710.05941\n",
        "\t\tThe hype was so huge that I could not help but try it\n",
        "\t\"\"\"\n",
        "\n",
        "\tdef __init__(self):\n",
        "\t\tsuper(Swish, self).__init__()\n",
        "\t\tself.s = nn.Sigmoid()\n",
        "\n",
        "\tdef forward(self, x):\n",
        "\t\treturn x * self.s(x)\n",
        "\n",
        "\n",
        "def act(act_fun='LeakyReLU'):\n",
        "\t'''\n",
        "\t\tEither string defining an activation function or module (e.g. nn.ReLU)\n",
        "\t'''\n",
        "\tif isinstance(act_fun, str):\n",
        "\t\tif act_fun == 'LeakyReLU':\n",
        "\t\t\treturn nn.LeakyReLU(0.2, inplace=True)\n",
        "\t\telif act_fun == 'Swish':\n",
        "\t\t\treturn Swish()\n",
        "\t\telif act_fun == 'ELU':\n",
        "\t\t\treturn nn.ELU()\n",
        "\t\telif act_fun == 'none':\n",
        "\t\t\treturn nn.Sequential()\n",
        "\t\telse:\n",
        "\t\t\tassert False\n",
        "\telse:\n",
        "\t\treturn act_fun()\n",
        "\n",
        "\n",
        "def bn(num_features):\n",
        "\treturn nn.BatchNorm2d(num_features)\n",
        "\n",
        "\n",
        "def conv(in_f, out_f, kernel_size, stride=1, bias=True, pad='zero', downsample_mode='stride'):\n",
        "\tdownsampler = None\n",
        "\tif stride != 1 and downsample_mode != 'stride':\n",
        "\n",
        "\t\tif downsample_mode == 'avg':\n",
        "\t\t\tdownsampler = nn.AvgPool2d(stride, stride)\n",
        "\t\telif downsample_mode == 'max':\n",
        "\t\t\tdownsampler = nn.MaxPool2d(stride, stride)\n",
        "\t\telif downsample_mode in ['lanczos2', 'lanczos3']:\n",
        "\t\t\tdownsampler = Downsampler(n_planes=out_f, factor=stride, kernel_type=downsample_mode, phase=0.5,\n",
        "\t\t\t\t\t\t\t\t\t  preserve_size=True)\n",
        "\t\telse:\n",
        "\t\t\tassert False\n",
        "\n",
        "\t\tstride = 1\n",
        "\n",
        "\tpadder = None\n",
        "\tto_pad = int((kernel_size - 1) / 2)\n",
        "\tif pad == 'reflection':\n",
        "\t\tpadder = nn.ReflectionPad2d(to_pad)\n",
        "\t\tto_pad = 0\n",
        "\n",
        "\tconvolver = nn.Conv2d(in_f, out_f, kernel_size, stride, padding=to_pad, bias=bias)\n",
        "\n",
        "\tlayers = filter(lambda x: x is not None, [padder, convolver, downsampler])\n",
        "\treturn nn.Sequential(*layers)\n",
        "\n",
        "def skip(\n",
        "  num_input_channels=2, num_output_channels=3,\n",
        "  num_channels_down=[16, 32, 64, 128, 128], num_channels_up=[16, 32, 64, 128, 128],\n",
        "  num_channels_skip=[4, 4, 4, 4, 4],\n",
        "  filter_size_down=3, filter_size_up=3, filter_skip_size=1,\n",
        "  need_sigmoid=True, need_bias=True,\n",
        "  pad='zero', upsample_mode='nearest', downsample_mode='stride', act_fun='LeakyReLU',\n",
        "  need1x1_up=True):\n",
        "  \"\"\"Assembles encoder-decoder with skip connections.\n",
        "\n",
        "  Arguments:\n",
        "    act_fun: Either string 'LeakyReLU|Swish|ELU|none' or module (e.g. nn.ReLU)\n",
        "    pad (string): zero|reflection (default: 'zero')\n",
        "    upsample_mode (string): 'nearest|bilinear' (default: 'nearest')\n",
        "    downsample_mode (string): 'stride|avg|max|lanczos2' (default: 'stride')\n",
        "\n",
        "  \"\"\"\n",
        "  assert len(num_channels_down) == len(num_channels_up) == len(num_channels_skip)\n",
        "\n",
        "  n_scales = len(num_channels_down)\n",
        "\n",
        "  if not (isinstance(upsample_mode, list) or isinstance(upsample_mode, tuple)):\n",
        "    upsample_mode = [upsample_mode] * n_scales\n",
        "\n",
        "  if not (isinstance(downsample_mode, list) or isinstance(downsample_mode, tuple)):\n",
        "    downsample_mode = [downsample_mode] * n_scales\n",
        "\n",
        "  if not (isinstance(filter_size_down, list) or isinstance(filter_size_down, tuple)):\n",
        "    filter_size_down = [filter_size_down] * n_scales\n",
        "\n",
        "  if not (isinstance(filter_size_up, list) or isinstance(filter_size_up, tuple)):\n",
        "    filter_size_up = [filter_size_up] * n_scales\n",
        "\n",
        "  last_scale = n_scales - 1\n",
        "\n",
        "  cur_depth = None\n",
        "\n",
        "  model = nn.Sequential()\n",
        "  model_tmp = model\n",
        "\n",
        "  input_depth = num_input_channels\n",
        "  for i in range(len(num_channels_down)):\n",
        "\n",
        "    deeper = nn.Sequential()\n",
        "    skip = nn.Sequential()\n",
        "\n",
        "    if num_channels_skip[i] != 0:\n",
        "      model_tmp.add(Concat(1, skip, deeper))\n",
        "    else:\n",
        "      model_tmp.add(deeper)\n",
        "\n",
        "    model_tmp.add(bn(num_channels_skip[i] + (num_channels_up[i + 1] if i < last_scale else num_channels_down[i])))\n",
        "\n",
        "    if num_channels_skip[i] != 0:\n",
        "      skip.add(conv(input_depth, num_channels_skip[i], filter_skip_size, bias=need_bias, pad=pad))\n",
        "      skip.add(bn(num_channels_skip[i]))\n",
        "      skip.add(act(act_fun))\n",
        "\n",
        "    # skip.add(Concat(2, GenNoise(nums_noise[i]), skip_part))\n",
        "\n",
        "    deeper.add(conv(input_depth, num_channels_down[i], filter_size_down[i], 2, bias=need_bias, pad=pad,\n",
        "            downsample_mode=downsample_mode[i]))\n",
        "    deeper.add(bn(num_channels_down[i]))\n",
        "    deeper.add(act(act_fun))\n",
        "\n",
        "    deeper.add(conv(num_channels_down[i], num_channels_down[i], filter_size_down[i], bias=need_bias, pad=pad))\n",
        "    deeper.add(bn(num_channels_down[i]))\n",
        "    deeper.add(act(act_fun))\n",
        "\n",
        "    deeper_main = nn.Sequential()\n",
        "\n",
        "    if i == len(num_channels_down) - 1:\n",
        "      # The deepest\n",
        "      k = num_channels_down[i]\n",
        "    else:\n",
        "      deeper.add(deeper_main)\n",
        "      k = num_channels_up[i + 1]\n",
        "\n",
        "    deeper.add(nn.Upsample(scale_factor=2, mode=upsample_mode[i]))\n",
        "\n",
        "    model_tmp.add(conv(num_channels_skip[i] + k, num_channels_up[i], filter_size_up[i], 1, bias=need_bias, pad=pad))\n",
        "    model_tmp.add(bn(num_channels_up[i]))\n",
        "    model_tmp.add(act(act_fun))\n",
        "\n",
        "    if need1x1_up:\n",
        "      model_tmp.add(conv(num_channels_up[i], num_channels_up[i], 1, bias=need_bias, pad=pad))\n",
        "      model_tmp.add(bn(num_channels_up[i]))\n",
        "      model_tmp.add(act(act_fun))\n",
        "\n",
        "    input_depth = num_channels_down[i]\n",
        "    model_tmp = deeper_main\n",
        "\n",
        "  model.add(conv(num_channels_up[0], num_output_channels, 1, bias=need_bias, pad=pad))\n",
        "  if need_sigmoid:\n",
        "    model.add(nn.Sigmoid())\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "def get_net(input_depth, NET_TYPE, pad, upsample_mode, n_channels=3, act_fun='LeakyReLU', skip_n33d=128, skip_n33u=128,\n",
        "\t\t\tskip_n11=4, num_scales=5, downsample_mode='stride'):\n",
        "\tif NET_TYPE == 'skip':\n",
        "\t\tnet = skip(input_depth, n_channels,\n",
        "\t\t\t\t   num_channels_down=[skip_n33d] * num_scales if isinstance(skip_n33d, int) else skip_n33d,\n",
        "\t\t\t\t   num_channels_up=[skip_n33u] * num_scales if isinstance(skip_n33u, int) else skip_n33u,\n",
        "\t\t\t\t   num_channels_skip=[skip_n11] * num_scales if isinstance(skip_n11, int) else skip_n11,\n",
        "\t\t\t\t   upsample_mode=upsample_mode, downsample_mode=downsample_mode,\n",
        "\t\t\t\t   need_sigmoid=True, need_bias=True, pad=pad, act_fun=act_fun)\n",
        "\n",
        "\treturn net\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "yf-rDRvG7QYv"
      },
      "outputs": [],
      "source": [
        "\n",
        "global aug\n",
        "global folder_name\n",
        "global logit_idx\n",
        "global RA_degrees\n",
        "global RA_translate\n",
        "global RandomGaussianBlur_kernelsize\n",
        "global sharpness\n",
        "global start_time\n",
        "global noise_on\n",
        "global cut_flag\n",
        "global normalize_on\n",
        "global input_noise\n",
        "\n",
        "\n",
        "start_time = time.time()\n",
        "sharpness = 0\n",
        "\n",
        "#torch.use_deterministic_algorithms(True, warn_only=True)\n",
        "seed = 1\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "random.seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "#sys.path.append(\"/home/mika/.conda/envs/py310/lib/python3.10/site-packages/torchvision/transforms/transforms.py\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def create_grid(batch_size, height, width):\n",
        "    \"\"\" Creates a grid with a batch size of batch_size,\n",
        "        2 channels, with given height and width \"\"\"\n",
        "    x = np.arange(width)\n",
        "    y = np.arange(height)\n",
        "    xv, yv = np.meshgrid(x, y)\n",
        "\n",
        "    # create torch tensors from numpy ndarrays\n",
        "    xv_t = torch.from_numpy(xv)\n",
        "    yv_t = torch.from_numpy(yv)\n",
        "\n",
        "    T = torch.stack((xv_t, yv_t))\n",
        "    grid = T.repeat(batch_size, 1, 1, 1)\n",
        "    return grid\n",
        "\n",
        "def fill_noise(x, noise_type):\n",
        "    \"\"\"Fills tensor `x` with noise of type `noise_type`.\"\"\"\n",
        "    if noise_type == 'u':\n",
        "        x.uniform_()\n",
        "    elif noise_type == 'n':\n",
        "        x.normal_()\n",
        "    else:\n",
        "        assert False\n",
        "\n",
        "\n",
        "def get_noise(input_depth, method, spatial_size, noise_type='u', var=1. / 10):\n",
        "    \"\"\"Returns a pytorch.Tensor of size (1 x `input_depth` x `spatial_size[0]` x `spatial_size[1]`)\n",
        "    initialized in a specific way.\n",
        "    Args:\n",
        "        input_depth: number of channels in the tensor\n",
        "        method: `noise` for fillting tensor with noise; `meshgrid` for np.meshgrid\n",
        "        spatial_size: spatial size of the tensor to initialize\n",
        "        noise_type: 'u' for uniform; 'n' for normal\n",
        "        var: a factor, a noise will be multiplicated by. Basically it is standard deviation scaler.\n",
        "    \"\"\"\n",
        "    if isinstance(spatial_size, int):\n",
        "        spatial_size = (spatial_size, spatial_size)\n",
        "    if method == 'noise':\n",
        "        shape = [torch.cuda.device_count(), input_depth, spatial_size[0], spatial_size[1]]\n",
        "        net_input = torch.zeros(shape)\n",
        "\n",
        "        fill_noise(net_input, noise_type)\n",
        "        net_input *= var\n",
        "    elif method == 'meshgrid':\n",
        "        assert input_depth == 2\n",
        "        X, Y = np.meshgrid(np.arange(0, spatial_size[1]) / float(spatial_size[1] - 1),\n",
        "                           np.arange(0, spatial_size[0]) / float(spatial_size[0] - 1))\n",
        "        meshgrid = np.concatenate([X[None, :], Y[None, :]])\n",
        "        net_input = np_to_torch(meshgrid)\n",
        "    else:\n",
        "        assert False\n",
        "    return net_input\n",
        "\n",
        "\n",
        "def create_input_normal(input_depth, sideY, sideX, batch_size):\n",
        "    # Create random input\n",
        "    net_input = torch.zeros([batch_size, input_depth, sideY, sideX], device=device).normal_().div(10).detach()\n",
        "    return net_input\n",
        "\n",
        "class MakeCutouts(torch.nn.Module):\n",
        "    def __init__(self, cut_size, cutn):\n",
        "        global cut_flag\n",
        "        super().__init__()\n",
        "        self.cut_size = cut_size\n",
        "        self.cutn = cutn\n",
        "        self.cutflag = cut_flag\n",
        "        # Compose image augmentations\n",
        "        kernel_size = int(RandomGaussianBlur_kernelsize), int(RandomGaussianBlur_kernelsize)\n",
        "        self.augs = torch.nn.Sequential(\n",
        "            K.RandomAffine(degrees=RA_degrees, translate=RA_translate, p=0.8, padding_mode='border',\n",
        "                           resample='bilinear'),\n",
        "            K.RandomHorizontalFlip(p=0.5),\n",
        "            K.RandomPerspective(0.45, p=0.8, resample='bilinear'),\n",
        "            K.RandomGrayscale(p=0.15),\n",
        "            K.RandomGaussianBlur(kernel_size, (0.1, 3)),\n",
        "            K.RandomSharpness(sharpness=sharpness, p=0.5, keepdim=True),\n",
        "            #K.RandomErasing(p=0.7)\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        sideY, sideX = input.shape[2:4]\n",
        "        if sideY != sideX:\n",
        "            input = K.RandomAffine(degrees=0, shear=10, p=0.5)(input)\n",
        "            # if sizes are different, shear the image, so it fits into a square\n",
        "\n",
        "        cutouts = []\n",
        "        cn_size = [self.cut_size, self.cut_size]\n",
        "\n",
        "        if self.cutflag:\n",
        "            max_size = min(sideX, sideY)\n",
        "            for cn in range(self.cutn):\n",
        "                if cn > self.cutn - self.cutn // 4:\n",
        "                    cutout = input\n",
        "                else:\n",
        "                    size = int(\n",
        "                        max_size * torch.zeros(1, ).normal_(mean=.8, std=.3).clip(float(self.cut_size / max_size), 1.))\n",
        "                    offsetx = torch.randint(0, sideX - size + 1, ())\n",
        "                    offsety = torch.randint(0, sideY - size + 1, ())\n",
        "                    cutout = input[:, :, offsety:offsety + size, offsetx:offsetx + size]\n",
        "                cutout = F.adaptive_avg_pool2d(cutout, self.cut_size)\n",
        "                cutouts.append(cutout)\n",
        "\n",
        "        else:\n",
        "            for cn in range(self.cutn):\n",
        "                cutout = input\n",
        "                cutout = F.avg_pool2d(cutout, kernel_size=4, stride=2, padding=1)\n",
        "                cutouts.append(cutout)\n",
        "\n",
        "        cutouts = torch.cat(cutouts)  # Concatenate cutouts - the rows\n",
        "        cutouts = self.augs(cutouts)\n",
        "        return cutouts\n",
        "\n",
        "\n",
        "def optimize_network(num_iterations, seed, input_depth, input_dims, optimizer_type, lr,\n",
        "                     lower_lr, display_rate, cut_size, cutn, results_folder, model, name=None):\n",
        "\n",
        "    loss_list = []\n",
        "\n",
        "    if seed is not None:\n",
        "        np.random.seed(seed)\n",
        "        torch.manual_seed(seed)\n",
        "        random.seed(seed)\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    # create results folder\n",
        "    if not os.path.isdir(results_folder):\n",
        "        os.makedirs(results_folder)\n",
        "\n",
        "    \"\"\"\n",
        "    # create results sub folder\n",
        "    full_sub_folder = results_folder + \"/\" + folder_name\n",
        "    if not os.path.isdir(full_sub_folder):\n",
        "        os.makedirs(full_sub_folder)\n",
        "    \"\"\"\n",
        "\n",
        "    make_cutouts = MakeCutouts(cut_size, cutn)\n",
        "    make_cutouts = nn.DataParallel(make_cutouts)\n",
        "\n",
        "    # Initialize DIP skip network\n",
        "    DIP_net = get_net(\n",
        "        input_depth, 'skip',\n",
        "        pad='reflection',\n",
        "        skip_n33d=128, skip_n33u=128,\n",
        "        skip_n11=4, num_scales=7,\n",
        "        upsample_mode='bilinear',\n",
        "    ).to(device)\n",
        "\n",
        "    DIP_net = nn.DataParallel(DIP_net)\n",
        "\n",
        "    # Initialize input noise\n",
        "    input_depth = input_dims[0]\n",
        "    sideY = input_dims[1]\n",
        "    sideX = input_dims[2]\n",
        "    # net_input = create_input_normal(input_depth, sideY, sideX, batch_size)\n",
        "\n",
        "    if input_noise:\n",
        "        net_input = get_noise(input_depth, 'noise', (sideY, sideX), noise_type='u', var=1. / 10)\n",
        "\n",
        "    else: # input is positional encoding\n",
        "        net_input = create_grid(batch_size= torch.cuda.device_count(), height = sideY, width = sideX)\n",
        "\n",
        "    net_input = net_input.type(torch.cuda.FloatTensor)\n",
        "    net_input.to(device)\n",
        "\n",
        "    if optimizer_type == 'Adam':\n",
        "        optimizer = torch.optim.Adam(DIP_net.parameters(), lr)\n",
        "    elif optimizer_type == 'MADGRAD':\n",
        "        optimizer = MADGRAD(DIP_net.parameters(), lr, weight_decay=0.01, momentum=0.9)\n",
        "\n",
        "    # get model\n",
        "    if model == \"VIT_B_16\":\n",
        "        classifier = torchvision.models.vit_b_16(\n",
        "            weights=torchvision.models.vision_transformer.ViT_B_16_Weights.IMAGENET1K_V1)\n",
        "        mean = [0.485, 0.456, 0.406]\n",
        "        std = [0.229, 0.224, 0.225]\n",
        "    if model == \"EFFICIENTNET\":\n",
        "        classifier = torchvision.models.efficientnet_v2_l(\n",
        "            weights=torchvision.models.EfficientNet_V2_L_Weights.IMAGENET1K_V1)\n",
        "        mean = [0.5, 0.5, 0.5]\n",
        "        std = [0.5, 0.5, 0.5]\n",
        "\n",
        "    classifier.to(device)\n",
        "    classifier.eval()\n",
        "    classifier = nn.DataParallel(classifier)\n",
        "\n",
        "    # training\n",
        "    #    try:\n",
        "    for i in range(num_iterations):\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        if noise_on:\n",
        "            if input_noise:\n",
        "                noise = get_noise(input_depth, 'noise', (sideY, sideX), noise_type='n', var=0.01)\n",
        "                # noise = noise.type(torch.cuda.FloatTensor)\n",
        "            else: # positional encoding\n",
        "                noise = get_noise(input_depth, 'noise', (sideY, sideX), noise_type='u', var=1.0)\n",
        "\n",
        "            noise = noise.to(device=device)\n",
        "            noisy_net_input = net_input + noise\n",
        "\n",
        "            with torch.cuda.amp.autocast():  # ops run in an op-specific dtype chosen by autocast to improve performance\n",
        "                dip_out = DIP_net(noisy_net_input).float()\n",
        "\n",
        "        else:\n",
        "            with torch.cuda.amp.autocast():  # ops run in an op-specific dtype chosen by autocast to improve performance\n",
        "                dip_out = DIP_net(net_input).float()  # run net on input\n",
        "\n",
        "        cutouts = make_cutouts(dip_out)\n",
        "\n",
        "        if normalize_on:\n",
        "            normalize_func = kornia.enhance.Normalize(mean, std)\n",
        "            cutouts = normalize_func(cutouts)\n",
        "\n",
        "        out = classifier(cutouts)\n",
        "        out = F.softmax(out, dim=1)\n",
        "        loss = 1 - out[:, logit_idx].mean()\n",
        "\n",
        "        loss_list.append(loss)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if ((i+1) % display_rate) == 0:\n",
        "            print(\"inside if\")\n",
        "            image = TF.to_pil_image(dip_out[0])\n",
        "            path = results_folder + \"/\" + f'{name}_res.png'\n",
        "            print(path)\n",
        "            image.save(path, quality=100)\n",
        "\n",
        "        if lower_lr:  # lower the learning rate over time - multiply by 0.99\n",
        "            optimizer.param_groups[0]['lr'] = max(0.00001, .99 * optimizer.param_groups[0]['lr'])\n",
        "\n",
        "        print(f'Iteration {i} of {num_iterations}')\n",
        "\n",
        "    # save DIP weights\n",
        "    #torch.save(DIP_net.state_dict(), full_sub_folder + \"/net\")\n",
        "    return dip_out[0], loss_list\n",
        "\n",
        "\n",
        "def train_net(results_folder, name=None):\n",
        "    global input_noise\n",
        "    global combine_models\n",
        "\n",
        "    num_iterations = 1000 #2500\n",
        "    seed = 1  # random.randint(0, 2 ** 32)\n",
        "    sideY = 512  # 512\n",
        "    sideX = 512  # 512\n",
        "    # logit_idx = 1 became global\n",
        "    optimizer_type = 'Adam'\n",
        "    lr = 1e-3\n",
        "    lower_lr = False\n",
        "    display_rate = 1000\n",
        "    cut_size = 224\n",
        "    cutn = 11\n",
        "    model = \"EFFICIENTNET\" #\"VIT_H_14\" # \"EFFICIENTNET\" #\"VIT_B_16\"\n",
        "    input_noise = 1  # determines if input is noise or positional encoding\n",
        "\n",
        "    if input_noise:\n",
        "        input_depth = 32\n",
        "    else: # positional encoding\n",
        "        input_depth = 2\n",
        "\n",
        "    input_dims = (input_depth, sideY, sideX)\n",
        "\n",
        "    out, loss_list = optimize_network(num_iterations, seed, input_depth, input_dims, optimizer_type, lr,\n",
        "                                      lower_lr, display_rate, cut_size, cutn, results_folder, model, name)\n",
        "\n",
        "    #create_config_file(num_iterations, seed, input_depth, sideY, sideX, optimizer_type, lr, lower_lr, cut_size, cutn,\n",
        "    #                   results_folder)\n",
        "    #create_loss_file(loss_list, results_folder)\n",
        "    #create_loss_graph(loss_list, results_folder)\n",
        "    #create_smooth_loss_graph(loss_list,results_folder)\n",
        "    #create_log_loss_graph(loss_list, results_folder)\n",
        "\n",
        "    return out\n",
        "\n",
        "\n",
        "def create_loss_file(loss_list, results_folder):\n",
        "    path = results_folder + \"/\" + folder_name + \"/Loss.txt\"\n",
        "    file = open(path, \"a\")\n",
        "    for i, loss in enumerate(loss_list):\n",
        "        text = f'Iterarion {i}: loss = {loss}\\n'\n",
        "        file.write(text)\n",
        "\n",
        "    file.close()\n",
        "\n",
        "\n",
        "def create_loss_graph(loss_list, results_folder):\n",
        "    path = results_folder + \"/\" + folder_name + \"/Loss.png\"\n",
        "    iterations = np.array(range(1, len(loss_list) + 1))\n",
        "    loss = np.array(loss_list)\n",
        "    plt.plot(iterations, loss, color='r', label='Loss')\n",
        "    plt.xlabel(\"Iteration\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"The Loss as a Function of the iteration number\")\n",
        "    plt.savefig(path)\n",
        "\n",
        "def create_smooth_loss_graph(loss_list,results_folder):\n",
        "    path = results_folder + \"/\" + folder_name + \"/Loss_smoothed.png\"\n",
        "    loss = torch.mean(torch.Tensor(loss_list).view(-1, 50), dim=1)\n",
        "    plt.plot(range(1, len(loss_list)//50 + 1), loss, color='r', label='Loss')\n",
        "    plt.xlabel(\"Iteration\")\n",
        "    plt.ylabel(\"Smooth Loss\")\n",
        "    plt.title(\"The 5 timestep mean Loss as a Function of the iteration number\")\n",
        "    plt.savefig(path)\n",
        "\n",
        "def create_log_loss_graph(loss_list, results_folder):\n",
        "    path = results_folder + \"/\" + folder_name + \"/Log_Loss.png\"\n",
        "    iterations = np.array(range(1, len(loss_list) + 1))\n",
        "    log = np.log(np.array(loss_list))\n",
        "    plt.plot(iterations, log, color='r', label='log(Loss)')\n",
        "    plt.xlabel(\"Iteration\")\n",
        "    plt.ylabel(\"Log(Loss)\")\n",
        "    plt.title(\"The Logarithm of the Loss as a Function of the iteration number\")\n",
        "    plt.savefig(path)\n",
        "\n",
        "def get_config(sharp_on, logit):\n",
        "    \"\"\"\n",
        "    assigns configuration\n",
        "    parameters to global variables\n",
        "    \"\"\"\n",
        "    global folder_name\n",
        "    global logit_idx\n",
        "    global RA_degrees\n",
        "    global RA_translate\n",
        "    global RandomGaussianBlur_kernelsize\n",
        "    global sharpness\n",
        "    global noise_on\n",
        "    global cut_flag\n",
        "    global normalize_on\n",
        "\n",
        "    folder_name = \"results\"\n",
        "    logit_idx = logit\n",
        "    RA_degrees = 30\n",
        "    RA_translate = 0.3\n",
        "    RandomGaussianBlur_kernelsize = 31\n",
        "    noise_on = 0\n",
        "    cut_flag = 1\n",
        "    normalize_on = 0\n",
        "    if sharp_on:\n",
        "        sharpness = 0\n",
        "\n",
        "def run_config(results_folder, sharp_on, logit, name=None):\n",
        "    \"\"\"\n",
        "    runs a config\n",
        "    \"\"\"\n",
        "    get_config(sharp_on, logit)\n",
        "    out = train_net(results_folder, name)\n",
        "    return out\n",
        "\n",
        "sharp_on = False\n",
        "results_folder_base = \"OUTPUTS\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run Code"
      ],
      "metadata": {
        "id": "hymrS3Lnfyi4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_folder = results_folder_base + class_name\n",
        "run_config(results_folder, True, class_number, name=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "JgWcmbktgD0r",
        "outputId": "d14cae9e-81a1-4a08-93df-7788028b335e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/efficientnet_v2_l-59c71312.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_v2_l-59c71312.pth\n",
            "100%|██████████| 455M/455M [00:05<00:00, 94.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0 of 1000\n",
            "Iteration 1 of 1000\n",
            "Iteration 2 of 1000\n",
            "Iteration 3 of 1000\n",
            "Iteration 4 of 1000\n",
            "Iteration 5 of 1000\n",
            "Iteration 6 of 1000\n",
            "Iteration 7 of 1000\n",
            "Iteration 8 of 1000\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-b269c0a8fb58>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mresults_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_folder_base\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrun_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_number\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-574504e98cca>\u001b[0m in \u001b[0;36mrun_config\u001b[0;34m(results_folder, sharp_on, logit, name)\u001b[0m\n\u001b[1;32m    376\u001b[0m     \"\"\"\n\u001b[1;32m    377\u001b[0m     \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msharp_on\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-574504e98cca>\u001b[0m in \u001b[0;36mtrain_net\u001b[0;34m(results_folder, name)\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0minput_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msideY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msideX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m     out, loss_list = optimize_network(num_iterations, seed, input_depth, input_dims, optimizer_type, lr,\n\u001b[0m\u001b[1;32m    296\u001b[0m                                       lower_lr, display_rate, cut_size, cutn, results_folder, model, name)\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-574504e98cca>\u001b[0m in \u001b[0;36moptimize_network\u001b[0;34m(num_iterations, seed, input_depth, input_dims, optimizer_type, lr, lower_lr, display_rate, cut_size, cutn, results_folder, model, name)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0mcutouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcutouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcutouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogit_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc_device_obj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m                     raise RuntimeError(\"module must have its parameters and buffers \"\n\u001b[1;32m    158\u001b[0m                                        \u001b[0;34m\"on device {} (device_ids[0]) but found one of \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}